{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Speech Recognition Experiments for Quiz Bowl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to evaluate if using ASR transcriptions, relative to original text, hurts Quiz Bowl performance.  The Analysis of 136 quiz bowl questions, correctly answered by inputs of both ASR and original text, demonstrates that the Quiz Bowl system needs to see 8.95% of an ASR transcribed question, but only 6.57% of the original text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import speech_recognition as sr\n",
    "import glob\n",
    "import subprocess\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Audio Data and Process with ASR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used to query Quiz Bowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_question(text):\n",
    "    response = requests.post(\n",
    "        'http://trantor.entilzha.io:5000/api/answer_question',\n",
    "        data={'text': text}\n",
    "    ).json()\n",
    "    return response['guess'], response['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate .wav files from Text to Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../qb/data/questions/expo/2015_hsnct.csv\n",
      "../../../../qb/data/questions/expo/2015_jennings.csv\n",
      "../../../../qb/data/questions/expo/2015_jennings.power.csv\n",
      "../../../../qb/data/questions/expo/2016_hsnct.csv\n",
      "../../../../qb/data/questions/expo/2016_naacl.csv\n",
      "../../../../qb/data/questions/expo/2017_hsnct.csv\n",
      "../../../../qb/data/questions/expo/2017_hsnct.power.csv\n"
     ]
    }
   ],
   "source": [
    "#stores questions by document\n",
    "storage = dict()\n",
    "\n",
    "#loop through each document (only CSV files in the QB data folder)\n",
    "for each_file in glob.glob('../../../../qb/data/questions/expo/*.csv'):\n",
    "    \n",
    "    print (each_file)\n",
    "    \n",
    "    with open(each_file) as f:\n",
    "        file_storage = []\n",
    "        \n",
    "        data = csv.reader(f)\n",
    "        \n",
    "        #dump header\n",
    "        header = next(data)\n",
    "        if \"text\" in header:\n",
    "            #find proper index of question text\n",
    "            correct_col = header.index(\"text\")\n",
    "            answer_col = header.index(\"answer\")\n",
    "            #keep track of question number\n",
    "            counter = 0\n",
    "            for line in data:\n",
    "                try:\n",
    "                    text = (line[correct_col])\n",
    "                    answer = (line[answer_col])\n",
    "                    file_dict = {}\n",
    "                    file_dict['text'] = text\n",
    "                    file_dict['answer'] = answer\n",
    "                    file_storage.append(file_dict)\n",
    "                    \n",
    "                    #convert into audio with gTTS, save it to mp3, convert it to WAV\n",
    "                    sentTTS = gTTS(text, lang='en', slow=True)\n",
    "                    file_name = each_file + \"_\" +str(counter) \n",
    "                    sentTTS.save(file_name+\".mp3\")\n",
    "                    subprocess.call(['ffmpeg', '-i', file_name+\".mp3\",\n",
    "                    file_name + '.wav'])\n",
    "                    counter += 1   \n",
    "                \n",
    "                except:\n",
    "                    print (\"Issue caused by \" + str(line))                      \n",
    "            storage[each_file] = file_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe Speech to Text with IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#update here - redacted for Github\n",
    "IBM_USERNAME = \"\"\n",
    "IBM_PASSWORD = \"\"\n",
    "\n",
    "processed_speech = []\n",
    "    \n",
    "record_data = dict()\n",
    "#Update file path as needed\n",
    "for each_file in glob.glob('../../../../qb/data/questions/expo/*.wav'):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(each_file) as source:              \n",
    "        audio = r.record(source)\n",
    "    #PocketSphinx is used locally to decipher the audio\n",
    "    audio_data = r.recognize_ibm(audio, IBM_USERNAME, IBM_PASSWORD)\n",
    "    #find the appropriate file and question number.  WAV files contain this information\n",
    "    #lower for bleu score calculation\n",
    "    text_data = storage[each_file[0:each_file.rfind('_')]][int(each_file [each_file.rfind('_')+1:each_file.rfind('.')])]['text'].lower() \n",
    "    answer = storage[each_file[0:each_file.rfind('_')]][int(each_file [each_file.rfind('_')+1:each_file.rfind('.')])]['answer'].lower()\n",
    "    \n",
    "    final_output = {}\n",
    "    final_output['answer_original'] = answer_question(text_data)\n",
    "    final_output['answer_asr'] = answer_question(audio_data)\n",
    "    final_output['original'] = text_data\n",
    "    final_output['transcribed'] = audio_data\n",
    "    final_output['answer'] = answer\n",
    "    \n",
    "    processed_speech.append(final_output)\n",
    "    #add pause to avoid spamming API\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JSON For Future Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exportable = { 'data': processed_speech}\n",
    "\n",
    "with open('expo.json', 'w') as fp:\n",
    "    json.dump(exportable, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('expo.json') as json_data:\n",
    "    d = json.load(json_data)\n",
    "    data = d['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identfy the cases in which the QB Prediction of ASR == the one on the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "agreement_batch = []\n",
    "\n",
    "for item in data:\n",
    "    if item['answer_original'][0].lower()  == item['answer'] == item['answer_asr'][0].lower():\n",
    "        storage = [item['original'], item['transcribed'], item['answer']] \n",
    "        agreement_batch.append(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the average words needed for the first accurate QB prediction - the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_original = 0\n",
    "avg_asr = 0\n",
    "original_results = []\n",
    "original_percentage = []\n",
    "count = 0\n",
    "\n",
    "for item in agreement_batch:\n",
    "    count += 1\n",
    "    if count%10 == 0:\n",
    "        print (count)\n",
    "    \n",
    "    words = item[0].split()\n",
    "    for i in range(2, len(item[0])):\n",
    "        query = answer_question(' '.join(words[0:i]))\n",
    "        if query[0].lower() == item[2]:\n",
    "            original_results.append(i)\n",
    "            original_percentage.append(float(i)/len(item[0]))\n",
    "            break\n",
    "        \n",
    "        if i == len(item[0]):\n",
    "            original_results.append(\"Something went wrong\")\n",
    "\n",
    "#Extra Code to see Avg Length of ASR and original text\n",
    "#avg_original += len(item[0].split())\n",
    "#avg_asr += len(item[1].split())\n",
    "#print (avg_original/len(agreement_batch), avg_asr/len(agreement_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the average words needed for the first accurate QB prediction - ASR Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asr_results = []\n",
    "asr_percentage = []\n",
    "count = 0\n",
    "\n",
    "for item in agreement_batch:\n",
    "    count += 1\n",
    "    if count%10 == 0:\n",
    "        print (count)\n",
    "        \n",
    "    count = 3\n",
    "    words = item[1].split()\n",
    "    for i in range(2, len(item[1])):\n",
    "        query = answer_question(' '.join(words[0:i]))\n",
    "        if query[0].lower() == item[2]:\n",
    "            asr_results.append(i)\n",
    "            asr_percentage.append(float(i)/len(item[1]))\n",
    "            break\n",
    "        \n",
    "        if i == len(item[1]):\n",
    "            asr_results.append(\"Something went wrong\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the original text\n",
      "17.345588235294116\n",
      "0.06570769705904247\n",
      "\n",
      "Statistics for the ASR Transcription\n",
      "25.794117647058822\n",
      "0.08956855146818574\n"
     ]
    }
   ],
   "source": [
    "print (\"Statistics for the original text\")\n",
    "print (statistics.mean(original_results))\n",
    "print (statistics.mean(original_percentage))\n",
    "print()\n",
    "print (\"Statistics for the ASR Transcription\")\n",
    "print (statistics.mean(asr_results))\n",
    "print (statistics.mean(asr_percentage))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
